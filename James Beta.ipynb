{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98a6c1d",
   "metadata": {},
   "source": [
    "# South African Language Identification Hack 2022\n",
    "***EDSA 2201 classification hackathon***\n",
    "\n",
    "**James Beta**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a55e6",
   "metadata": {},
   "source": [
    "This notebook serves as the workspace for the hackathon submitted on kaggle.\n",
    "\n",
    "The notebook is ordered as follows;\n",
    "1. Imports\n",
    "2. Exploratory Data Analysis\n",
    "3. Data Cleaning and Feature Engineering\n",
    "4. Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680bcacb",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will begin by importing all necessary packages to explore the data, clean out unwante features, create relevant features and build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Import the feature selector module\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_set.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae26089",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "In this section we explore our data by applying non-technical analysis to understand the structure and contents of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0652b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00509ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title): \n",
    "    title = re.sub('<.*?>', ' ', title)\n",
    "    #pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+' #Pattern to remove all hyperlinks\n",
    "    #title = re.sub(pattern_url,' ',title)    \n",
    "    #title = re.sub('RT @.*:','',title)    \n",
    "    title = re.sub('[^a-zA-Z#]', ' ',title) \n",
    "    #title = re.sub(r'(\\s)#\\w+','',title)  \n",
    "    title = title.lower()\n",
    "    title = ' '.join(title.split())\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['cleaned_message'] = df_train['text'].apply(clean_title)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2326d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = sns.countplot(x=df_train['lang_id'],  data=df_train, order = df_train['lang_id'].value_counts().index )\n",
    "for p, label in zip(ax.patches, df_train['lang_id'].value_counts()):   \n",
    "    ax.annotate(label, (p.get_x()+0.25, p.get_height()+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295e0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faf0fff0",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Engineering\n",
    "\n",
    "now that we understand what the dataset contains, proceed to prepare the data for modelling by removing all unwanted/ unnecessary information and working on transforming the data into a useful format ready for the next stage which is model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc20c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect = CountVectorizer()\n",
    "# X_count = vect.fit_transform(df_train['cleaned_message'].values.astype(str))\n",
    "vect_20 = CountVectorizer(lowercase=True, max_features = 11000)\n",
    "X_count = vect_20.fit_transform(df_train['cleaned_message'].values.astype(str))\n",
    "X_count.shape\n",
    "X = vect_20.fit_transform(df_train['cleaned_message'].values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb047ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train['cleaned_message']\n",
    "y = df_train['lang_id']\n",
    "# vectorization clean training data \n",
    "vectorizer = TfidfVectorizer(min_df=2,  max_df=0.9,\n",
    "                             ngram_range=(3, 6), analyzer=('char'))\n",
    "features = vectorizer.fit_transform(x)\n",
    "labels = df_train['lang_id']\n",
    "\n",
    "# Fit label encoder and return encoded labels\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(y)\n",
    "# List of label encoder types to use for lookup \n",
    "type_labels = list(le.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b406cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, Y,test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec19725",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fed173",
   "metadata": {},
   "source": [
    "In this section we use the features extracted from our data to build our classification model.\n",
    "The model is then assesed based on its ability to classify the test data by identifying the language a tweet is written in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e881c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_kbest = LogisticRegression(random_state = 42, multi_class='ovr', n_jobs = 1, C = 1e5, max_iter = 4000)\n",
    "# Set up selector, choosing score function and number of features to retain\n",
    "selector_kbest = feature_selection.SelectKBest(score_func=f_classif, k=5000)\n",
    "\n",
    "# Transform the training data\n",
    "X_train_kbest = selector_kbest.fit_transform(X_train, y_train)\n",
    "# Fit model to the transformed data\n",
    "lm_kbest.fit(X_train_kbest, y_train)\n",
    "X_test_kbest = selector_kbest.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d21a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_set.csv')\n",
    "df_test['cleaned_message'] = df_test['text'].apply(clean_title)\n",
    "\n",
    "test_features = vectorizer.transform(df_test.cleaned_message)\n",
    "test_features = selector_kbest.transform(test_features)\n",
    "new_pred = lm_kbest.predict(test_features)\n",
    "\n",
    "df_test['lang_id'] = list(le.inverse_transform(new_pred))\n",
    "sub = df_test[['index','lang_id']]\n",
    "sub = sub.set_index('index')\n",
    "sub.to_csv('Submission16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lm_kbest, selector_kbest.transform(X_test), y_test)  \n",
    "figsize=(10, 10)\n",
    "plt.title('Logistic Regression Model Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(cr, title='Classification report ', with_avg_total=False, cmap=plt.cm.Blues):\n",
    "\n",
    "    lines = cr.split('n')\n",
    "\n",
    "    classes = []\n",
    "    plotMat = []\n",
    "    for line in lines[2 : (len(lines) - 3)]:\n",
    "        #print(line)\n",
    "        t = line.split()\n",
    "        # print(t)\n",
    "        classes.append(t[0])\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        print(v)\n",
    "        plotMat.append(v)\n",
    "\n",
    "    if with_avg_total:\n",
    "        aveTotal = lines[len(lines) - 1].split()\n",
    "        classes.append('avg/total')\n",
    "        vAveTotal = [float(x) for x in t[1:len(aveTotal) - 1]]\n",
    "        plotMat.append(vAveTotal)\n",
    "\n",
    "\n",
    "    plt.imshow(plotMat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    x_tick_marks = np.arange(3)\n",
    "    y_tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45)\n",
    "    plt.yticks(y_tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xlabel('Measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm_kbest.predict(selector_kbest.transform(X_test))\n",
    "classificationReport = classification_report(y_test, y_pred, target_names=target_names)\n",
    "\n",
    "plot_classification_report(classificationReport, title = 'Logistic Regression Model Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db1a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_set.csv')\n",
    "df_test['cleaned_message'] = df_test['text'].apply(clean_title)\n",
    "\n",
    "test_features = vectorizer.transform(df_test.text)\n",
    "new_pred1 = model.predict(test_features)\n",
    "\n",
    "df_test['lang_id'] = list(le.inverse_transform(new_pred1))\n",
    "# df_test.rename(columns={'pred':'lang_id'},inplace=True)\n",
    "sub = df_test[['index','lang_id']]\n",
    "sub = sub.set_index('index')\n",
    "sub.to_csv('Submission17.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a8dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ypred1 = model.predict(X_test)\n",
    "plot_confusion_matrix(model, X_test, y_test)  \n",
    "figsize=(10, 10)\n",
    "\n",
    "plt.title('Naive Bayes Model Results')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationReport = classification_report(y_test, ypred1, target_names=target_names)\n",
    "\n",
    "plot_classification_report(classificationReport, title = 'Naive Bayes Model Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression model for training \n",
    "lm_model = LogisticRegression(random_state = 42, multi_class='ovr', n_jobs = 1, C = 1e5, max_iter = 4000)\n",
    "lm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d938916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_set.csv')\n",
    "df_test['cleaned_message'] = df_test['text'].apply(clean_title)\n",
    "test_features = vectorizer.transform(df_test.cleaned_message)\n",
    "new_pred2 = lm_model.predict(test_features)\n",
    "\n",
    "df_test['lang_id'] = list(le.inverse_transform(new_pred2))\n",
    "# df_test.rename(columns={'pred':'lang_id'},inplace=True)\n",
    "sub = df_test[['index','lang_id']]\n",
    "sub = sub.set_index('index')\n",
    "sub.to_csv('Submission18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58567b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred2 = lm_model.predict(X_test)\n",
    "plot_confusion_matrix(lm_model, X_test, y_test)\n",
    "figsize=(10, 10)\n",
    "plt.title('Logistic Regression Model (Kbest) Results')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationReport = classification_report(y_test, ypred2, target_names=target_names)\n",
    "\n",
    "plot_classification_report(classificationReport, title = 'Logistic Regression Model (Kbest) Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8596618",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = LinearSVC(penalty='l2',multi_class='ovr')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "df_test = pd.read_csv('test_set.csv')\n",
    "df_test['cleaned_message'] = df_test['text'].apply(clean_title)\n",
    "test_features = vectorizer.transform(df_test.cleaned_message)\n",
    "new_pred3 = svm_model.predict(test_features)\n",
    "df_test['lang_id'] = list(le.inverse_transform(new_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1eb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.rename(columns={'pred':'lang_id'},inplace=True)\n",
    "sub = df_test[['index','lang_id']]\n",
    "sub = sub.set_index('index')\n",
    "sub.to_csv('Submission19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc904294",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred3 = svm_model.predict(X_test)\n",
    "plot_confusion_matrix(svm_model, X_test, y_test)\n",
    "figsize=(10, 10)\n",
    "plt.title('Support Vector Classifier Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationReport = classification_report(y_test, ypred3, target_names=target_names)\n",
    "\n",
    "plot_classification_report(classificationReport, title = 'Logistic Regression Model (Kbest) Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Logistic Regression', 'Logistic regression with K-best features', 'Naive Bayes',  'Linear SVC']\n",
    "model_list = [lm_model, lm_kbest, model, svm_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba593f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_performance = []\n",
    "Training_performance = []\n",
    "for x in model_list:\n",
    "    if x == lm_kbest:\n",
    "        Training_performances = x.score(X_train_kbest, y_train)\n",
    "        Training_performance.append(Training_performances)\n",
    "        Testing_performances = x.score(X_test_kbest, y_test)\n",
    "        Testing_performance.append(Testing_performances)\n",
    "    else:\n",
    "        Training_performances = x.score(X_train, y_train)\n",
    "        Training_performance.append(Training_performances)\n",
    "        Testing_performances = x.score(X_test, y_test)\n",
    "        Testing_performance.append(Testing_performances)\n",
    "dict1 = {'Model': model_names, 'Training Performance': Training_performance, 'Testing Performance': Testing_performance}\n",
    "Model_df = pd.DataFrame(dict1)\n",
    "Model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.30  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "rects1 = ax.bar(x - width/2, Training_performance, width, label='Training Performance')\n",
    "rects2 = ax.bar(x + width/2, Training_performance, width, label='Testing Performance')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Model Performance')\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_title('Performance on Training and Test Sets')\n",
    "ax.set_xticks(x, model_names)\n",
    "box = ax.get_position()\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d6916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
